---
title: "LLMs for Exploratory Research"
output: html_notebook
---

# Large Language Models (LLMs) for Exploratory Research

Welcome to the LLMs for Exploratory Research workshop.

In a fast evolving artificial intelligence landscape, LLMs such as GPT have become a common buzzword. In the research community, their advantages and pitfalls are hotly debated. In this workshop, we will explore different chatbots powered by LLMs, beyond just ChatGPT. Our main goal will be to understand how LLMs can be used by researchers to conduct early-stage (or exploratory) research. Throughout the workshop, we will discuss best practices for prompt engineering and heuristics to evaluate the suitability of an LLM's output for our research purposes. Though the workshop primarily focuses on early-stage research, we will briefly discuss the use cases of LLMs in later stages of research, such as data analysis and writing.

## Learning Objectives

Our goals for today's workshop are:

1.  Explore different chatbots powered by Large Language Models (LLMs).

2.  Explore use cases for LLMs in exploratory research.

3.  Compare and contrast output from different LLMs.

Throughout this workshop series, we will use the following icons:

üîî **Question**: A quick question to help you understand what's going on.

ü•ä **Challenge**: Interactive exercise. We'll go through these in the workshop!

‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.

üí° **Tip**: How to do something a bit more efficiently or effectively.

üìù **Poll**: A zoom poll to help you learn.

üé¨ **Demo**: Showing off something more advanced so you know what you can use LLMs for in the future

## Introduction

We are probably all familiar with ChatGPT which uses an LLM called GPT, either having used it ourselves or heard about it.

üí° **Note:** There is a difference between an LLM and an LLM-powered chatbot [(Source: Zapier)](https://zapier.com/blog/chatgpt-vs-gpt/).

[![](images/clipboard-2620794215.png){style="display: block; margin: 1em auto" width="300"}](https://zapier.com/blog/chatgpt-vs-gpt/)

There are several LLMs beyond GPT that can be useful for research.

üîî **Question**: Have you heard of any other LLMs besides GPT or LLM-powered chatbots besides ChatGPT?

In today's workshop, we will explore a handful of LLMs that can be used through chatbots on the internet and do not require local installation. Note that most of these have free versions with limited capabilities and to access the full host of features, paid subscriptions are required. We will be working with free versions of most LLMs. However, all UC Berkeley affiliates have access to the premium version of Perplexity, which gives us access to GPT-4 and Claude 3. To activate your free Perplexity Pro account, you can sign up with your Berkeley email address on [this link](https://www.perplexity.ai/).

We will explore the interface of the following LLM-powered AI chatbots in today's workshop:

-   ChatGPT (uses GPT)

-   Perplexity Pro (uses GPT and Claude)

-   Claude.ai (uses Claude 3.5 Sonnet)

-   Phind (uses Phind Model)

Note that these are only four of several chatbots powered by different LLMs. Many others, such as Meta's Llama and Google's Gemini, can be used for various research tasks as well.

In today's workshop we will explore the uses of these LLMs following the structure of an exploratory research process.

-   We will start by using an LLM to come up with a research question.

-   Then, we will explore existing literature on that research question using an LLM.

-   We will take the help of an LLM to come up with a potential research design to answer our research question.

-   We will end with using an LLM to come up with a structure for our research paper.

## Stage 1: Framing a Research Question

There are many different ways to choose a research question - you may start with a dataset, an empirical observation about the world, or two variables that seem to be associated with each other. Being able to articulate a precise research question, regardless of where you start, is important for a strong introduction to any paper.

üîî **Question**: How do you usually come up with research questions in your field?

Today, we will use the findings of an existing paper to explore some research questions that emerge from them. The paper by Bode and Vraga (2020) asks how people on the internet perceive the correction of online misinformation.

### ü•ä Challenge 1: Designing a Research Question with LLMs

Using an LLM (you can choose between ChatGPT, Perplexity Pro, Claude.ai, and Phind), come up with a research question about peer to peer correction based on the findings in the Bode and Vraga (2020) paper. For this, you will have to upload the paper onto one of the platforms before you enter your query.

## Stage 2: Exploring Existing Literature

Once you've chosen a research question, you will want to know what other scholars have written about the topic and how your research fits into the literature. For this, you conduct a literature review, reading and summarizing papers that relate to your topic. There are some LLMs, such as [Consensus](https://consensus.app/?home=true), that draw from research libraries and can be a starting point for finding papers and summarizing existing literature on your topic.

### üé¨ **Demo**: Running a search on Consensus

Consensus combines its own LLM, that draws from academic papers hosted on Semantic Scholar, and GPT-4 that helps summarize findings to present links to papers on a topic. Let's see what happens when I run a query on a topic I am familiar with!

üí° **Tip**: Make sure to always double check the output from any LLM. Your existing knowledge about a topic will come in handy to ensure that the output for your query is accurate!

More than providing complete and accurate literature reviews, LLMs can be very helpful in summarizing specific papers. How do you get these models to give you most accurate summaries of papers and most relevant information? One possible model to follow is asking it for the paper's: research question, argument, hypotheses, methods, and results. We can also ask for critiques of a paper or extensions of the research.

### ü•ä Challenge 2: Summarizing Papers

Using the same paper you had uploaded previously, compare the outputs from two LLMs (ChatGPT versus Perplexity Pro) when you ask them the following question: ‚ÄúCan you provide a summary of the results on pages 8 to 14 of this paper?‚Äù Which output has more detail and specificity? Which LLM gave you a faster output? If you wanted more specificity from either LLM, what could you change about your prompt?

üí° **Tip**: The way you write your queries can determine the output from the LLM. Here are some resources from companies that have designed [LLMs](https://platform.openai.com/docs/guides/prompt-engineering) and LLM-based [chatbots](https://www.perplexity.ai/hub/faq/prompting-tips-and-examples-on-perplexity) on [prompt engineering](https://github.com/dair-ai/Prompt-Engineering-Guide), which has become a whole [industry](https://www.promptingguide.ai/) in itself.

You could summarize several individual papers like this by uploading them. You could then create a spreadsheet of all the papers you‚Äôve read and then upload the spreadsheet to an LLM to give you a summary of the field!

## Stage 3: Testing the Research Question

Once you have determined a research question and situated it within the broader literature on the topic, you will need an effective research design to test the research question. LLMs can be very helpful in coming with potential research designs!

### ü•ä Challenge 3: Research Design Preparation

Using an LLM of your choice, come up with a potential research design for the following research question: ‚ÄúWhat factors influence whether someone engages in peer-to-peer correction on social media? How do attitudes towards peer-to-peer correction differ depending on the topic being corrected (e.g. health misinformation vs. political misinformation)?‚Äù What level of detail do you ask for in your prompt? What would you need to change or adapt from the output of the LLM when you implement the design for your paper?

## Stage 4: Structuring a Paper

Before looking for data and conducting analysis for your research question, you might want a structure for your research paper to ensure it will flow correctly. Perhaps, you have a paper in your field of study that you particularly like. You can ask an LLM to analyze the structure of that paper and use it for your own.

### ü•ä Challenge 4: Asking an LLM to Analyze Paper Structure

Using the same paper you uploaded previously, ask an LLM of your choice to analyze the structure of that paper. Make sure to specify the level of detail you want in the output. For instance, do you want the LLM to give you broad section headers? Do you want the output to include how the structure could be adapted to your research question? You may need to use multiple queries to address this challenge!

üí° **Tip**: Make sure to think about how you would change the structure of the paper to suit your needs, for instance, a journal's requirements for a submission.

## Post-Exploratory Phase of Research

There are plenty of other use cases for LLMs in research beyond the exploratory phase. Most commonly, researchers use LLMs to assist them in coding, which includes debugging code or writing code more efficiently, or even learning about a new package or new language! The D-Lab offers a workshop on using [GitHub Copilot](https://github.com/dlab-berkeley/Copilot-Fundamentals) to assist with coding in R. Here are some resources you can reference when thinking about coding using LLMs:

-   [Tips](https://www.enthought.com/blog/seven-pro-tips-for-scientists-use-llms-to-code/) to code using AI

-   [Paper](https://arxiv.org/abs/2304.10778) evaluating coding responses across three LLMs

-   [Resources](https://www.infoworld.com/article/2338386/8-chatgpt-tools-for-r-programming.html) and best practices when using ChatGPT with R

LLMs can also help you edit your papers, provide feedback on your writing, or even offer critiques of your work, allowing you to get ahead of what reviewers at journals might say! All of these functionalities would only require you to upload your paper and ask the right questions from the model.

## Key Points

LLMs are a powerful tool if used correctly by researchers. In this workshop, we discussed the use of LLMs and AI-powered chatbots in conducting early-stage research. Specifically, we covered using LLMs to:

-   Come up with research questions drawn from the shortcomings or as extensions of existing work.
-   Summarize existing papers on a topic of interest.
-   Create a research design that will help test the research question.
-   Structure a research paper in the most effective way by asking the model to analyze the structure of a paper that we would like to emulate.

‚ö†Ô∏è **Heads-up**: Remember, the output of a model is only as good as the input we provide, which means to get the best out of an LLM, we need to ask the right questions and always remember to check the output. Your knowledge as a researcher is invaluable because LLMs can still give us incorrect or incomplete answers!

## Resources

-   [Copilot Fundamentals](https://github.com/dlab-berkeley/Copilot-Fundamentals) workshop

-   [Python GPT Fundamentals](https://github.com/dlab-berkeley/Python-GPT-Fundamentals) workshop

-   Non-technical [blog](https://www.oneusefulthing.org/p/scaling-the-state-of-play-in-ai) on how scaling works in training models
